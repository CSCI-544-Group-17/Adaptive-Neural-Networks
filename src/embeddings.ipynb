{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:16.592838Z",
     "start_time": "2023-10-27T05:40:16.587343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is: /Users/swapnildhanwal/Documents/USC/CSCI 544/Project/csci-544-project/src\n",
      "['embeddings.ipynb', 'training.ipynb', 'embeddings.py', 'main.py', 'data.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_READ_PATH = None\n",
    "EMBEDDINGS_WRITE_PATH = None\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_name = 'CSCI544-Project'\n",
    "    folder_path = f'/content/drive/MyDrive/{folder_name}'\n",
    "    os.chdir(folder_path)\n",
    "    print(\"Current working directory is: \" + os.getcwd())\n",
    "    BASE_READ_PATH = \"./data/\"\n",
    "    EMBEDDINGS_WRITE_PATH = \"./t5p_small_embeddings/\"\n",
    "except:\n",
    "    BASE_READ_PATH = \"../data/\"\n",
    "    EMBEDDINGS_WRITE_PATH = \"../t5p_small_embeddings/\"\n",
    "finally:\n",
    "    print(\"Current working directory is: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: transformers in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (4.33.2)\r\n",
      "Requirement already satisfied: filelock in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (3.12.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (0.17.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (2023.8.8)\r\n",
      "Requirement already satisfied: requests in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (0.3.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from requests->transformers) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/swapnildhanwal/Library/Python/3.8/lib/python/site-packages (from requests->transformers) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:20.302170Z",
     "start_time": "2023-10-27T05:40:18.656807Z"
    }
   },
   "id": "9547cc19db2641b1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:21.182421Z",
     "start_time": "2023-10-27T05:40:21.179700Z"
    }
   },
   "id": "4774f1d5e06e89e4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "CHECKPOINT = \"Salesforce/codet5p-110m-embedding\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(CHECKPOINT, trust_remote_code=True)\n",
    "MODEL = AutoModel.from_pretrained(CHECKPOINT, trust_remote_code=True).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:26.507530Z",
     "start_time": "2023-10-27T05:40:23.880201Z"
    }
   },
   "id": "15735973ce39f4ca"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_code_embedding(code: str):\n",
    "    inputs = TOKENIZER.encode(code, return_tensors=\"pt\").to(DEVICE)\n",
    "    embedding = MODEL(inputs)[0]\n",
    "    embedding_np_array = embedding.reshape(-1, embedding.shape[0]).cpu().detach().numpy()\n",
    "    del embedding\n",
    "    return embedding_np_array\n",
    "\n",
    "\n",
    "def get_and_save_embeddings(file_name: str, _type: str):\n",
    "    read_path = \"%s%s/%s\" % (BASE_READ_PATH, _type, file_name)\n",
    "    write_path = \"%s%s/%s\" % (EMBEDDINGS_WRITE_PATH, _type, file_name)\n",
    "    num_lines = get_file_length(read_path)\n",
    "    with open(read_path, \"r\") as f_read:\n",
    "        i = 0\n",
    "        with open(write_path, \"w\") as f_write:\n",
    "            with tqdm(total=num_lines) as bar:\n",
    "                for line in f_read.readlines():\n",
    "                    if i % 30 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        code = data[\"func_before\"]\n",
    "                        embeddings = get_code_embedding(code)\n",
    "                        label = int(data[\"vul\"])\n",
    "                        result = {\"embeddings\": embeddings.tolist(), \"label\": label}\n",
    "                        f_write.write(json.dumps(result) + \"\\n\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                    finally:\n",
    "                        i += 1\n",
    "                        bar.update()\n",
    "\n",
    "\n",
    "def get_file_length(file_path):\n",
    "    count = 0\n",
    "    with open(file_path, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while True:\n",
    "            if not line:\n",
    "                break\n",
    "            count += 1\n",
    "            line = f.readline()\n",
    "    return count\n",
    "\n",
    "\n",
    "def main(_type: str):\n",
    "    for file_name in os.listdir(\"%s%s/\" % (BASE_READ_PATH, _type)):\n",
    "        print(\"Generating embeddings for: \" + file_name)\n",
    "        get_and_save_embeddings(file_name, _type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:27.180225Z",
     "start_time": "2023-10-27T05:40:27.175251Z"
    }
   },
   "id": "7ba0348aa5d85701"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for: train_0.jsonl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../t5p_small_embeddings/train/train_0.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m _type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_type\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 49\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(_type)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file_name \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (BASE_READ_PATH, _type)):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating embeddings for: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m file_name)\n\u001B[0;32m---> 49\u001B[0m     \u001B[43mget_and_save_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_type\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 15\u001B[0m, in \u001B[0;36mget_and_save_embeddings\u001B[0;34m(file_name, _type)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(read_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f_read:\n\u001B[1;32m     14\u001B[0m     i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mwrite_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f_write:\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39mnum_lines) \u001B[38;5;28;01mas\u001B[39;00m bar:\n\u001B[1;32m     17\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f_read\u001B[38;5;241m.\u001B[39mreadlines():\n",
      "File \u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../t5p_small_embeddings/train/train_0.jsonl'"
     ]
    }
   ],
   "source": [
    "_type = \"train\"\n",
    "main(_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:40:28.223757Z",
     "start_time": "2023-10-27T05:40:28.144831Z"
    }
   },
   "id": "b5a5300b727bfe51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T01:42:36.845205Z",
     "start_time": "2023-10-26T01:42:36.842950Z"
    }
   },
   "id": "eddfc1fdbe6085a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
