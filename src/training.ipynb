{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is: /Users/swapnildhanwal/Documents/USC/CSCI 544/Project/csci-544-project\n",
      "['embeddings', '.DS_Store', 'defect', 'sample', '.git', 'data', '.idea', 'src']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_name = 'CSCI544-Project'\n",
    "    folder_path = f'/content/drive/MyDrive/{folder_name}'\n",
    "    os.chdir(folder_path)\n",
    "    print(\"Current working directory is: \" + os.getcwd())\n",
    "    print(os.listdir())\n",
    "except:\n",
    "    os.chdir(\"../\")\n",
    "finally:\n",
    "    print(\"Current working directory is: \" + os.getcwd())\n",
    "    print(os.listdir())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T22:34:42.613857Z",
     "start_time": "2023-10-25T22:34:42.607938Z"
    }
   },
   "id": "f13562788b1721fe"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T22:37:29.763308Z",
     "start_time": "2023-10-25T22:37:28.900101Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BASE_EMBEDDINGS_PATH = \"./t5p_small_embeddings/\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T22:37:31.393451Z",
     "start_time": "2023-10-25T22:37:31.389275Z"
    }
   },
   "id": "dd668745ab2942d1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_tensors(file_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(BASE_EMBEDDINGS_PATH + file_name) as f:\n",
    "        line = f.readline()\n",
    "        while True:\n",
    "            if not line:\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            X.append(data[\"embeddings\"])\n",
    "            y.append(data[\"label\"])\n",
    "            line = f.readline()\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32).clone().detach().to(DEVICE).reshape(-1, 256)\n",
    "    y = torch.tensor(y, dtype=torch.float32).clone().detach().to(DEVICE).reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 1),\n",
    "        nn.Sigmoid()\n",
    "    ).to(DEVICE)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model, loss_fn, optimizer\n",
    "\n",
    "def train(model, loss_fn, optimizer, X: torch.tensor, y: torch.tensor, n_epochs: int, batch_size: int):\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            Xbatch = X[i:i+batch_size]\n",
    "            y_pred = model(Xbatch)\n",
    "            ybatch = y[i:i+batch_size]\n",
    "            loss = loss_fn(y_pred, ybatch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "\n",
    "def f1_score(y_true, y_pred, threshold=0.5, eps=1e-8):\n",
    "    y_pred_binarized = (y_pred > threshold).float()\n",
    "    tp = (y_true * y_pred_binarized).sum(dim=0)\n",
    "    fp = ((1 - y_true) * y_pred_binarized).sum(dim=0)\n",
    "    fn = (y_true * (1 - y_pred_binarized)).sum(dim=0)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + eps)\n",
    "    return f1\n",
    "\n",
    "def evaluate(model: nn.Sequential, X, y):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X)\n",
    "    accuracy = (y_pred.round() == y).float().mean()\n",
    "    print(f\"Accuracy {accuracy}\")\n",
    "    print(f1_score(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T22:37:32.315944Z",
     "start_time": "2023-10-25T22:37:32.310833Z"
    }
   },
   "id": "d505011d8a1a59e7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './t5p_small_embeddings/train_0.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain_0.jsonl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(y\u001B[38;5;241m.\u001B[39mshape)\n",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m, in \u001B[0;36mload_tensors\u001B[0;34m(file_name)\u001B[0m\n\u001B[1;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mBASE_EMBEDDINGS_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      5\u001B[0m     line \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreadline()\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './t5p_small_embeddings/train_0.jsonl'"
     ]
    }
   ],
   "source": [
    "X, y = load_tensors(\"train_0.jsonl\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T22:37:35.310857Z",
     "start_time": "2023-10-25T22:37:35.174895Z"
    }
   },
   "id": "74d1dd746dda2e4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/swapnildhanwal/Documents/USC/CSCI 544/Project/csci-544-project/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:53:56.896173Z",
     "start_time": "2023-10-08T20:53:56.888362Z"
    }
   },
   "id": "cd92617cdf34d3a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5482064efc68590d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
